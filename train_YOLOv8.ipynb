{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iirKR8q-0Uzy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "ROOT_DIR = 'D:\\Pemrograman\\Python\\Project\\Yolov8\\\\'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ea4cf7c1a28b469da774875cb5965619",
            "065d28c1c9ac464ea886da3f3d1c97c0",
            "1fed4c2df09b45cb9ebcdb7867d3699c",
            "16af2f967d84404888ba78d533f1bcc6",
            "d5dc116c1e10461494702924b98dcf7b",
            "3940caf66fa24c6caf706ea674631d44",
            "84bb2421481749d1a5f8b4d37b489916",
            "ff17bc5ad9fd4869ba7f83784b95fcfc",
            "24b033e6caa14549afb142f6ba8439dd",
            "1da2f666fa8d4131ac42a321bf6665d5",
            "f4fd8a63388e43879608452c3e926db8"
          ]
        },
        "id": "-bwQ63HG0oLT",
        "outputId": "1de80ae7-6eda-4fdb-f89f-c26b20c4ba4a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.Conv                  [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.Conv                  [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.C2f                   [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.Conv                  [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.C2f                   [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.C2f                   [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.C2f                   [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.SPPF                  [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.C2f                   [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.C2f                   [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.Conv                  [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.C2f                   [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.Conv                  [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.C2f                   [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.Detect                [80, [64, 128, 256]]          \n",
            "YOLOv8n summary: 225 layers, 3157200 parameters, 3157184 gradients, 8.9 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "New https://pypi.org/project/ultralytics/8.0.66 available  Update with 'pip install -U ultralytics'\n",
            "Ultralytics YOLOv8.0.61  Python-3.9.7 torch-1.13.1+cu116 CPU\n",
            "\u001b[34m\u001b[1myolo\\engine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.yaml, data=D:\\Pemrograman\\Python\\Project\\Yolov8\\config.yaml, epochs=10, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, hide_labels=False, hide_conf=False, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, fl_gamma=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=d:\\pemrograman\\python\\project\\yolov8\\ultralytics\\runs\\detect\\train19\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.Conv                  [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.Conv                  [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.C2f                   [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.Conv                  [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.C2f                   [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.C2f                   [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.C2f                   [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.SPPF                  [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.C2f                   [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.C2f                   [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.Conv                  [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.C2f                   [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.Conv                  [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.C2f                   [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.Detect                [1, [64, 128, 256]]           \n",
            "YOLOv8n summary: 225 layers, 3011043 parameters, 3011027 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "WARNING  ClearML installed but not initialized correctly, not logging this run. It seems ClearML is not configured on this machine!\n",
            "To get started with ClearML, setup your own 'clearml-server' or create a free account at https://app.clear.ml\n",
            "Setup instructions can be found here: https://clear.ml/docs\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir d:\\pemrograman\\python\\project\\yolov8\\ultralytics\\runs\\detect\\train19', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias\n",
            "train: Scanning D:\\Pemrograman\\Python\\Project\\Yolov8\\data\\train\\labels...:   0%|          | 0/251 [00:00<?, ?it/s]Scanning D:\\Pemrograman\\Python\\Project\\Yolov8\\data\\train\\labels... 54 images, 0 backgrounds, 0 corrupt:  22%|██▏       | 54/251 [00:00<00:00, 519.30it/s]Scanning D:\\Pemrograman\\Python\\Project\\Yolov8\\data\\train\\labels... 123 images, 0 backgrounds, 0 corrupt:  49%|████▉     | 123/251 [00:00<00:00, 600.71it/s]Scanning D:\\Pemrograman\\Python\\Project\\Yolov8\\data\\train\\labels... 184 images, 1 backgrounds, 0 corrupt:  73%|███████▎  | 184/251 [00:00<00:00, 589.11it/s]Scanning D:\\Pemrograman\\Python\\Project\\Yolov8\\data\\train\\labels... 251 images, 1 backgrounds, 0 corrupt: 100%|██████████| 251/251 [00:00<00:00, 617.71it/s]Scanning D:\\Pemrograman\\Python\\Project\\Yolov8\\data\\train\\labels... 251 images, 1 backgrounds, 0 corrupt: 100%|██████████| 251/251 [00:00<00:00, 599.07it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: D:\\Pemrograman\\Python\\Project\\Yolov8\\data\\train\\labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "val: Scanning D:\\Pemrograman\\Python\\Project\\Yolov8\\data\\val\\labels...:   0%|          | 0/53 [00:00<?, ?it/s]Scanning D:\\Pemrograman\\Python\\Project\\Yolov8\\data\\val\\labels... 53 images, 0 backgrounds, 0 corrupt: 100%|██████████| 53/53 [00:00<00:00, 623.66it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: D:\\Pemrograman\\Python\\Project\\Yolov8\\data\\val\\labels.cache\n",
            "Plotting labels to d:\\pemrograman\\python\\project\\yolov8\\ultralytics\\runs\\detect\\train19\\labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1md:\\pemrograman\\python\\project\\yolov8\\ultralytics\\runs\\detect\\train19\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/10         0G      1.105      3.065      1.492         17        640: 100%|██████████| 16/16 [02:19<00:00,  8.69s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:08<00:00,  4.23s/it]\n",
            "                   all         53         68    0.00415      0.971      0.385      0.189\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/10         0G      1.024      2.404      1.406         13        640: 100%|██████████| 16/16 [01:53<00:00,  7.07s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:08<00:00,  4.17s/it]\n",
            "                   all         53         68    0.00415      0.971       0.59      0.345\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/10         0G       1.08      1.993      1.425         12        640: 100%|██████████| 16/16 [01:53<00:00,  7.08s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:08<00:00,  4.11s/it]\n",
            "                   all         53         68    0.00987      0.868       0.57      0.306\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/10         0G      1.071      1.715      1.402         16        640: 100%|██████████| 16/16 [01:55<00:00,  7.21s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:08<00:00,  4.29s/it]\n",
            "                   all         53         68      0.897      0.256      0.742      0.452\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/10         0G     0.9997      1.516      1.342         16        640: 100%|██████████| 16/16 [01:53<00:00,  7.07s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:08<00:00,  4.13s/it]\n",
            "                   all         53         68      0.881      0.588      0.757      0.447\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/10         0G     0.9832      1.434      1.339         13        640: 100%|██████████| 16/16 [01:50<00:00,  6.90s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:08<00:00,  4.19s/it]\n",
            "                   all         53         68      0.779       0.57      0.713      0.438\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/10         0G     0.9804      1.337      1.291         11        640: 100%|██████████| 16/16 [01:51<00:00,  6.98s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:08<00:00,  4.10s/it]\n",
            "                   all         53         68       0.77      0.737      0.774      0.521\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/10         0G     0.9691       1.31      1.318         12        640: 100%|██████████| 16/16 [01:51<00:00,  6.96s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:08<00:00,  4.13s/it]\n",
            "                   all         53         68      0.828      0.691      0.832      0.523\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/10         0G     0.9744      1.237      1.273         16        640: 100%|██████████| 16/16 [01:49<00:00,  6.86s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:08<00:00,  4.04s/it]\n",
            "                   all         53         68       0.73      0.765       0.78      0.508\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/10         0G     0.9562      1.227      1.271         14        640: 100%|██████████| 16/16 [01:48<00:00,  6.77s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:08<00:00,  4.18s/it]\n",
            "                   all         53         68      0.846      0.706      0.844      0.548\n",
            "\n",
            "10 epochs completed in 0.343 hours.\n",
            "Optimizer stripped from d:\\pemrograman\\python\\project\\yolov8\\ultralytics\\runs\\detect\\train19\\weights\\last.pt, 6.2MB\n",
            "Optimizer stripped from d:\\pemrograman\\python\\project\\yolov8\\ultralytics\\runs\\detect\\train19\\weights\\best.pt, 6.2MB\n",
            "\n",
            "Validating d:\\pemrograman\\python\\project\\yolov8\\ultralytics\\runs\\detect\\train19\\weights\\best.pt...\n",
            "Ultralytics YOLOv8.0.61  Python-3.9.7 torch-1.13.1+cu116 CPU\n",
            "YOLOv8n summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:07<00:00,  3.53s/it]\n",
            "                   all         53         68      0.848      0.706      0.844      0.547\n",
            "Speed: 1.9ms preprocess, 104.2ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
            "Results saved to \u001b[1md:\\pemrograman\\python\\project\\yolov8\\ultralytics\\runs\\detect\\train19\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "model = YOLO(\"yolov8n.yaml\").load('yolov8n.pt')\n",
        "model.train(data='D:\\Pemrograman\\Python\\Project\\Yolov8\\config.yaml',epochs = 10,batch=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_path = r'ultralytics\\runs\\detect\\train19\\weights\\best.pt'\n",
        "\n",
        "own_model = YOLO(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.0.61  Python-3.9.7 torch-1.13.1+cu116 CPU\n",
            "YOLOv8n summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "val: Scanning D:\\Pemrograman\\Python\\Project\\Yolov8\\data\\val\\labels.cache... 53 images, 0 backgrounds, 0 corrupt: 100%|██████████| 53/53 [00:00<?, ?it/s]Scanning D:\\Pemrograman\\Python\\Project\\Yolov8\\data\\val\\labels.cache... 53 images, 0 backgrounds, 0 corrupt: 100%|██████████| 53/53 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:07<00:00,  1.90s/it]\n",
            "                   all         53         68      0.863      0.691      0.836      0.542\n",
            "Speed: 1.9ms preprocess, 111.5ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
            "Results saved to \u001b[1md:\\pemrograman\\python\\project\\yolov8\\ultralytics\\runs\\detect\\val14\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "ultralytics.yolo.utils.metrics.DetMetrics object with attributes:\n",
              "\n",
              "ap_class_index: array([0])\n",
              "box: ultralytics.yolo.utils.metrics.Metric object\n",
              "confusion_matrix: <ultralytics.yolo.utils.metrics.ConfusionMatrix object at 0x000001AF81BC24F0>\n",
              "fitness: 0.5717634787592784\n",
              "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
              "maps: array([    0.54243])\n",
              "names: {0: 'Panda'}\n",
              "plot: True\n",
              "results_dict: {'metrics/precision(B)': 0.8629334820964738, 'metrics/recall(B)': 0.6911764705882353, 'metrics/mAP50(B)': 0.8357977308125968, 'metrics/mAP50-95(B)': 0.542426339642243, 'fitness': 0.5717634787592784}\n",
              "save_dir: WindowsPath('d:/pemrograman/python/project/yolov8/ultralytics/runs/detect/val14')\n",
              "speed: {'preprocess': 1.948109212911354, 'inference': 111.45098254365742, 'loss': 0.0, 'postprocess': 2.4467999080442033}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "own_model.val()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "image 1/1 D:\\Pemrograman\\Python\\Project\\Yolov8\\data\\train\\images\\00000000.jpg: 448x640 1 Panda, 312.2ms\n",
            "Speed: 3.0ms preprocess, 312.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[ultralytics.yolo.engine.results.Results object with attributes:\n",
              " \n",
              " _keys: ('boxes', 'masks', 'probs')\n",
              " boxes: ultralytics.yolo.engine.results.Boxes object\n",
              " keys: ['boxes']\n",
              " masks: None\n",
              " names: {0: 'Panda'}\n",
              " orig_img: array([[[ 40,  53,  61],\n",
              "         [ 40,  53,  61],\n",
              "         [ 38,  54,  61],\n",
              "         ...,\n",
              "         [  8, 197, 165],\n",
              "         [ 12, 197, 163],\n",
              "         [  9, 194, 160]],\n",
              " \n",
              "        [[ 37,  50,  58],\n",
              "         [ 38,  51,  59],\n",
              "         [ 36,  52,  59],\n",
              "         ...,\n",
              "         [  7, 197, 166],\n",
              "         [  8, 197, 165],\n",
              "         [  5, 194, 162]],\n",
              " \n",
              "        [[ 36,  48,  58],\n",
              "         [ 36,  48,  58],\n",
              "         [ 34,  49,  58],\n",
              "         ...,\n",
              "         [  0, 197, 166],\n",
              "         [  0, 196, 166],\n",
              "         [  0, 194, 164]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 14,  10,   5],\n",
              "         [ 12,   8,   3],\n",
              "         [ 11,   7,   2],\n",
              "         ...,\n",
              "         [ 59, 134, 113],\n",
              "         [ 66, 131, 115],\n",
              "         [ 69, 132, 116]],\n",
              " \n",
              "        [[ 10,   6,   1],\n",
              "         [  9,   5,   0],\n",
              "         [ 10,   6,   1],\n",
              "         ...,\n",
              "         [ 58, 133, 112],\n",
              "         [ 66, 131, 115],\n",
              "         [ 69, 132, 116]],\n",
              " \n",
              "        [[  8,   4,   0],\n",
              "         [  8,   4,   0],\n",
              "         [ 10,   6,   1],\n",
              "         ...,\n",
              "         [ 57, 132, 111],\n",
              "         [ 66, 131, 115],\n",
              "         [ 70, 133, 117]]], dtype=uint8)\n",
              " orig_shape: (500, 750)\n",
              " path: 'D:\\\\Pemrograman\\\\Python\\\\Project\\\\Yolov8\\\\data\\\\train\\\\images\\\\00000000.jpg'\n",
              " probs: None\n",
              " speed: {'preprocess': 3.002643585205078, 'inference': 312.18862533569336, 'postprocess': 0.9992122650146484}]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "own_model(source='./data/train/images/00000000.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 448x640 1 Panda, 119.0ms\n",
            "Speed: 1.0ms preprocess, 119.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1md:\\pemrograman\\python\\project\\yolov8\\ultralytics\\runs\\detect\\predict4\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# from ndarray\n",
        "im2 = cv2.imread('./data/train/images/00000000.jpg')\n",
        "results = own_model.predict(source=im2, save=True)  # save plotted images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 384x640 2 Pandas, 89.0ms\n",
            "Speed: 3.0ms preprocess, 89.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1md:\\pemrograman\\python\\project\\yolov8\\ultralytics\\runs\\detect\\predict4\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# from PIL\n",
        "im1 = Image.open(\"./data/val/images/00000321.jpg\")\n",
        "results = own_model.predict(source=im1, save=True)  # save plotted images"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "ab4cfb695e4995928d8d48b937410e7989a45ba361d6003efd8e9b7b9498f677"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "065d28c1c9ac464ea886da3f3d1c97c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3940caf66fa24c6caf706ea674631d44",
            "placeholder": "​",
            "style": "IPY_MODEL_84bb2421481749d1a5f8b4d37b489916",
            "value": "100%"
          }
        },
        "16af2f967d84404888ba78d533f1bcc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1da2f666fa8d4131ac42a321bf6665d5",
            "placeholder": "​",
            "style": "IPY_MODEL_f4fd8a63388e43879608452c3e926db8",
            "value": " 755k/755k [00:00&lt;00:00, 18.8MB/s]"
          }
        },
        "1da2f666fa8d4131ac42a321bf6665d5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fed4c2df09b45cb9ebcdb7867d3699c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff17bc5ad9fd4869ba7f83784b95fcfc",
            "max": 773236,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_24b033e6caa14549afb142f6ba8439dd",
            "value": 773236
          }
        },
        "24b033e6caa14549afb142f6ba8439dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3940caf66fa24c6caf706ea674631d44": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84bb2421481749d1a5f8b4d37b489916": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5dc116c1e10461494702924b98dcf7b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea4cf7c1a28b469da774875cb5965619": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_065d28c1c9ac464ea886da3f3d1c97c0",
              "IPY_MODEL_1fed4c2df09b45cb9ebcdb7867d3699c",
              "IPY_MODEL_16af2f967d84404888ba78d533f1bcc6"
            ],
            "layout": "IPY_MODEL_d5dc116c1e10461494702924b98dcf7b"
          }
        },
        "f4fd8a63388e43879608452c3e926db8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff17bc5ad9fd4869ba7f83784b95fcfc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
